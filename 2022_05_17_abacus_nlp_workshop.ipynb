{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sratnaparkhi/tensorflow/blob/main/2022_05_17_abacus_nlp_workshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ace4015",
      "metadata": {
        "id": "1ace4015"
      },
      "outputs": [],
      "source": [
        "!pip install -U abacusai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1d5feac",
      "metadata": {
        "id": "a1d5feac"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "import threading\n",
        "import time\n",
        "\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import IPython.display\n",
        "\n",
        "import abacusai"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13b5208a",
      "metadata": {
        "id": "13b5208a"
      },
      "source": [
        "# Set up API client and load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "458ea55a",
      "metadata": {
        "id": "458ea55a"
      },
      "outputs": [],
      "source": [
        "api_key = 'api key goes here'\n",
        "server = 'https://abacus.ai'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95995fa2",
      "metadata": {
        "id": "95995fa2"
      },
      "outputs": [],
      "source": [
        "api_client = abacusai.ApiClient(api_key=api_key, server=server)\n",
        "api_client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78b567e6",
      "metadata": {
        "id": "78b567e6"
      },
      "outputs": [],
      "source": [
        "feature_group = api_client.describe_feature_group('feature group id goes here')\n",
        "data = feature_group.load_as_pandas()\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0935f2f8",
      "metadata": {
        "id": "0935f2f8"
      },
      "source": [
        "# Get predictions from sentiment model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ec2ade2",
      "metadata": {
        "id": "3ec2ade2"
      },
      "outputs": [],
      "source": [
        "# Replace this code with code in predictions API screen\n",
        "\n",
        "from abacusai import PredictionClient\n",
        "client = PredictionClient()\n",
        "client.get_sentiment(deployment_token='deployment token goes here', deployment_id='deployment id goes here',\n",
        "                     document=\"I love my car, it's awesome!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd4c041f",
      "metadata": {
        "id": "fd4c041f"
      },
      "outputs": [],
      "source": [
        "sent_deployment_token = 'deployment token goes here'\n",
        "sent_deployment_id = 'deployment id goes here'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7746606",
      "metadata": {
        "id": "a7746606"
      },
      "outputs": [],
      "source": [
        "tqdm._instances.clear()\n",
        "sample_texts = data['review'][:100]\n",
        "sentiments = [\n",
        "    client.get_sentiment(\n",
        "        deployment_token=sent_deployment_token,\n",
        "        deployment_id=sent_deployment_id,\n",
        "        document=text\n",
        "    )\n",
        "    for text in tqdm(sample_texts)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4aae3d8",
      "metadata": {
        "id": "b4aae3d8"
      },
      "outputs": [],
      "source": [
        "query = 'joy'\n",
        "print(f'Top scoring texts for: \"{query}\"\\n')\n",
        "scores = [s[query] for s in sentiments]\n",
        "arg_sort = np.argsort(-np.array(scores))\n",
        "for i in arg_sort[:5]:\n",
        "    print(scores[i])\n",
        "    print(sample_texts[i])\n",
        "    print('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30a99586",
      "metadata": {
        "id": "30a99586"
      },
      "outputs": [],
      "source": [
        "query = 'annoyance'\n",
        "print(f'Top scoring texts for: \"{query}\"\\n')\n",
        "scores = [s[query] for s in sentiments]\n",
        "arg_sort = np.argsort(-np.array(scores))\n",
        "for i in arg_sort[:5]:\n",
        "    print(scores[i])\n",
        "    print(sample_texts[i])\n",
        "    print('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28ff9381",
      "metadata": {
        "id": "28ff9381"
      },
      "outputs": [],
      "source": [
        "query = 'fear'\n",
        "print(f'Top scoring texts for: \"{query}\"\\n')\n",
        "scores = [s[query] for s in sentiments]\n",
        "arg_sort = np.argsort(-np.array(scores))\n",
        "for i in arg_sort[:5]:\n",
        "    print(scores[i])\n",
        "    print(sample_texts[i])\n",
        "    print('')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d76674c2",
      "metadata": {
        "id": "d76674c2"
      },
      "source": [
        "# Create a classification model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c79d4303",
      "metadata": {
        "id": "c79d4303"
      },
      "outputs": [],
      "source": [
        "print('Creating project')\n",
        "class_project = api_client.create_project('nlp_classification', use_case='NLP_CLASSIFICATION')\n",
        "\n",
        "api_client.add_feature_group_to_project(\n",
        "    feature_group_id=feature_group, project_id=class_project, feature_group_type='DOCUMENTS'\n",
        ")\n",
        "\n",
        "class_project.set_feature_mapping(\n",
        "    feature_group_id=feature_group,\n",
        "    feature_name='review',\n",
        "    feature_mapping='DOCUMENT',\n",
        ")\n",
        "\n",
        "print('Training model')\n",
        "class_model = class_project.train_model(\n",
        "    name='classification_model_1',\n",
        "    training_config={\n",
        "        'zero_shot_hypotheses': [\n",
        "            'This text is about car speed / acceleration / slowness',\n",
        "            'This text is about car price / cost / value for money',\n",
        "            'This text is about car build quality',\n",
        "            'This text is about car seats',\n",
        "        ]\n",
        "    }\n",
        ")\n",
        "\n",
        "class_model = class_model.wait_for_full_automl()\n",
        "print('Deploying model')\n",
        "class_deployment = api_client.create_deployment(model_id=class_model)\n",
        "class_deployment = class_deployment.wait_for_deployment()\n",
        "class_deployment_token = class_project.create_deployment_token()\n",
        "class_deployment_id = class_deployment.deployment_id\n",
        "\n",
        "print('Model deployed')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69a3c102",
      "metadata": {
        "id": "69a3c102"
      },
      "outputs": [],
      "source": [
        "print('Testing prediction')\n",
        "client.get_classification(\n",
        "    deployment_token=class_deployment_token,\n",
        "    deployment_id=class_deployment_id,\n",
        "    document=\"This car is a bargain.\"\n",
        ")\n",
        "\n",
        "sample_texts = data['review'][:100]\n",
        "text_classifications = []\n",
        "\n",
        "text_to_prediction = {}\n",
        "\n",
        "print('Producing predictions')\n",
        "\n",
        "# Produce predictions in the background so we can do some analysis straight away\n",
        "\n",
        "def process_data(texts):\n",
        "    for text in texts:\n",
        "        text_to_prediction[text] = client.get_classification(\n",
        "            deployment_token=class_deployment_token,\n",
        "            deployment_id=class_deployment_id,\n",
        "            document=text,\n",
        "        )\n",
        "        \n",
        "thread = threading.Thread(target=process_data, args=(sample_texts,))\n",
        "thread.start()\n",
        "\n",
        "while len(text_to_prediction) < 20:\n",
        "    IPython.display.clear_output(wait=True)\n",
        "    print(f'Predictions produced so far: {len(text_to_prediction)}')\n",
        "    time.sleep(1)\n",
        "print('Example prediction:')\n",
        "list(text_to_prediction.values())[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8acbf22",
      "metadata": {
        "id": "d8acbf22"
      },
      "outputs": [],
      "source": [
        "predictions = []\n",
        "for text in sample_texts:\n",
        "    if text not in text_to_prediction:\n",
        "        break\n",
        "    else:\n",
        "        predictions.append(text_to_prediction[text])\n",
        "print(f'Predictions made so far: {len(predictions)}\\n')\n",
        "query = list(predictions[0].keys())[1]\n",
        "print(f'Top scoring texts for: \"{query}\"\\n')\n",
        "scores = [s[query] for s in predictions]\n",
        "arg_sort = np.argsort(-np.array(scores))\n",
        "for i in arg_sort[:5]:\n",
        "    print(f'Score = {scores[i]}')\n",
        "    print(sample_texts[i])\n",
        "    print('')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2973945",
      "metadata": {
        "id": "f2973945"
      },
      "source": [
        "# Build a named entity recognition (NER) model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "645be391",
      "metadata": {
        "id": "645be391"
      },
      "outputs": [],
      "source": [
        "ner_project = api_client.create_project('named_entity_recognition', use_case='NAMED_ENTITY_RECOGNITION')\n",
        "\n",
        "api_client.add_feature_group_to_project(\n",
        "    feature_group_id=feature_group, project_id=ner_project, feature_group_type='DOCUMENTS'\n",
        ")\n",
        "\n",
        "ner_project.set_feature_mapping(\n",
        "    feature_group_id=feature_group,\n",
        "    feature_name='review',\n",
        "    feature_mapping='DOCUMENT',\n",
        ")\n",
        "\n",
        "ner_model = ner_project.train_model(\n",
        "    name='ner_model_1',\n",
        "    training_config={'NER_MODEL_TYPE': \"pretrained uncased 43 categories\"}\n",
        ")\n",
        "\n",
        "ner_model.wait_for_full_automl()\n",
        "\n",
        "ner_deployment = api_client.create_deployment(model_id=ner_model)\n",
        "\n",
        "ner_deployment = ner_deployment.wait_for_deployment()\n",
        "\n",
        "ner_deployment_token = ner_project.create_deployment_token()\n",
        "\n",
        "ner_deployment_id = ner_deployment.deployment_id\n",
        "ner_deployment_token = ner_deployment_token\n",
        "\n",
        "client.get_labels(deployment_token=ner_deployment_token, deployment_id=ner_deployment_id, query_data={\"content\":\"I love my Toyota Camry!\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17ed4a48",
      "metadata": {
        "id": "17ed4a48"
      },
      "outputs": [],
      "source": [
        "tqdm._instances.clear()\n",
        "sample_texts = data['review'][:100]\n",
        "annotations = [\n",
        "    client.get_labels(deployment_token=ner_deployment_token, deployment_id=ner_deployment_id, query_data={'content': text})['annotations']\n",
        "    for text in tqdm(sample_texts)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6aba53fd",
      "metadata": {
        "id": "6aba53fd"
      },
      "outputs": [],
      "source": [
        "label_counts = collections.Counter([anno['displayName'] for anno_list in annotations for anno in anno_list])\n",
        "label_counts.most_common(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1411db68",
      "metadata": {
        "id": "1411db68"
      },
      "outputs": [],
      "source": [
        "product_counts = collections.Counter([anno['textExtraction']['textSegment']['phrase'].strip().lower()\n",
        "                                      for anno_list in annotations for anno in anno_list if anno['displayName'] == 'product'])\n",
        "product_counts.most_common(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d70bd419",
      "metadata": {
        "id": "d70bd419"
      },
      "source": [
        "# Combined analysis using multiple models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b460b843",
      "metadata": {
        "id": "b460b843"
      },
      "outputs": [],
      "source": [
        "# Filter using NER\n",
        "\n",
        "filtered_texts = [\n",
        "    text\n",
        "    for text, anno_list in zip(sample_texts, annotations)\n",
        "    if any([anno['displayName'] == 'product' and 'avalon' in anno['textExtraction']['textSegment']['phrase'].strip().lower()\n",
        "           for anno in anno_list])\n",
        "]\n",
        "len(filtered_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2a30bde",
      "metadata": {
        "id": "b2a30bde"
      },
      "outputs": [],
      "source": [
        "# See top scores after the filter\n",
        "\n",
        "predictions = []\n",
        "for text in filtered_texts:\n",
        "    if text not in text_to_prediction:\n",
        "        break\n",
        "    else:\n",
        "        predictions.append(text_to_prediction[text])\n",
        "query = list(predictions[0].keys())[1]\n",
        "print(f'Top scoring texts for: \"{query}\"\\n')\n",
        "scores = [s[query] for s in predictions]\n",
        "arg_sort = np.argsort(-np.array(scores))\n",
        "for i in arg_sort[:5]:\n",
        "    print(scores[i])\n",
        "    print(filtered_texts[i])\n",
        "    print('')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "2022-05-17-abacus-nlp-workshop.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}